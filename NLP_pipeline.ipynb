{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impressive-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unknown-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "optical-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['the company has gained a value of $9.4 million as compared to the costs of 2.7$ million last year.', 'The company had a great year and gained twelve billion dollars with a loss of $1.2b.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "general-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(texts,  disable = 'pareser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ancient-walnut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$9.4 million MONEY\n",
      "2.7$ million MONEY\n",
      "last year DATE\n",
      "a great year DATE\n",
      "twelve billion dollars MONEY\n",
      "1.2b MONEY\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-secret",
   "metadata": {},
   "source": [
    "## Hashtag and Emoji Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "affected-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emoji = [\"ğŸ˜€\", \"ğŸ˜ƒ\", \"ğŸ˜‚\", \"ğŸ¤£\", \"ğŸ˜Š\", \"ğŸ˜\"]  # Positive emoji\n",
    "neg_emoji = [\"ğŸ˜\", \"ğŸ˜ \", \"ğŸ˜©\", \"ğŸ˜¢\", \"ğŸ˜­\", \"ğŸ˜’\"]  # Negative emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pregnant-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [[{'ORTH': emoji}] for emoji in pos_emoji]\n",
    "neg = [[{'ORTH': emoji}] for emoji in neg_emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spiritual-entry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ORTH': 'ğŸ˜€'}],\n",
       " [{'ORTH': 'ğŸ˜ƒ'}],\n",
       " [{'ORTH': 'ğŸ˜‚'}],\n",
       " [{'ORTH': 'ğŸ¤£'}],\n",
       " [{'ORTH': 'ğŸ˜Š'}],\n",
       " [{'ORTH': 'ğŸ˜'}]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "forward-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "delayed-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    if doc.vocab.strings[match_id] == 'happy':\n",
    "        doc.sentiment += 0.1\n",
    "    elif doc.vocab.strings[match_id] == 'sad':\n",
    "        doc.sentiment -= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "graduate-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('happy', pos, on_match=label_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "patient-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('sad', neg, on_match=label_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "weighted-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('HASHTAG', [[{'ORTH': '#'}, {'IS_ASCII': True}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "intellectual-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Hello guys ğŸ˜€ğŸ˜‚ #kgptalkie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "marked-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "gothic-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy ğŸ˜€\n",
      "happy ğŸ˜‚\n",
      "HASHTAG #kgptalkie\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(string_id, span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-convenience",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
